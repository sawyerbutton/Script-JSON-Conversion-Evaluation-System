#!/usr/bin/env python3
"""
ç³»ç»Ÿæµ‹è¯•è„šæœ¬
ç”¨äºå¿«é€Ÿæµ‹è¯•è¯„ä¼°ç³»ç»Ÿæ˜¯å¦æ­£å¸¸å·¥ä½œ
"""

import os
import sys
from pathlib import Path

# æ·»åŠ srcåˆ°è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent / "src"))

from evaluators.main_evaluator import EvaluationConfig, ScriptEvaluator  # noqa: E402


def test_basic_evaluation():
    """æµ‹è¯•åŸºæœ¬è¯„ä¼°åŠŸèƒ½"""

    print("=" * 60)
    print("å‰§æœ¬JSONè½¬æ¢è¯„ä¼°ç³»ç»Ÿ - ç³»ç»Ÿæµ‹è¯•")
    print("=" * 60)

    # é…ç½®è¯„ä¼°å™¨
    config = EvaluationConfig(
        use_deepseek_judge=False,  # æµ‹è¯•æ—¶å…³é—­LLMè¯„ä¼°ï¼ˆé¿å…APIè°ƒç”¨ï¼‰
        run_consistency_check=False,
        save_detailed_report=True,
        save_html_report=False,
    )

    print("\né…ç½®è¯„ä¼°å™¨...")
    evaluator = ScriptEvaluator(config)

    # å‡†å¤‡æµ‹è¯•æ•°æ®
    test_case = {
        "source_text": """å†…æ™¯ å’–å•¡é¦† - æ—¥

æé›·ååœ¨è§’è½é‡Œï¼Œä¸å®‰åœ°çœ‹ç€æ‰‹è¡¨ã€‚éŸ©æ¢…æ¢…æ¨é—¨è€Œå…¥ï¼Œè¡¨æƒ…å†·æ¼ ã€‚

éŸ©æ¢…æ¢…
ï¼ˆå†·æ·¡åœ°ï¼‰
ä½ æƒ³è¯´ä»€ä¹ˆï¼Ÿ

æé›·
ï¼ˆç´§å¼ ï¼‰
æ¢…æ¢…ï¼Œå…³äºæ˜¨æ™šçš„äº‹...

éŸ©æ¢…æ¢…
ä¸ç”¨è§£é‡Šäº†ã€‚æˆ‘éƒ½çœ‹åˆ°äº†ã€‚

éŸ©æ¢…æ¢…è½¬èº«è¦èµ°ï¼Œæé›·æ€¥å¿™æ‹‰ä½å¥¹çš„æ‰‹ã€‚

æé›·
è¯·å¬æˆ‘è¯´å®Œï¼é‚£ä¸æ˜¯ä½ æƒ³çš„é‚£æ ·ï¼

éŸ©æ¢…æ¢…ç”©å¼€ä»–çš„æ‰‹ï¼Œçœ¼ä¸­å«æ³ªã€‚

éŸ©æ¢…æ¢…
å¤Ÿäº†ã€‚æˆ‘ä»¬ç»“æŸäº†ã€‚

å¥¹å¿«æ­¥ç¦»å¼€ï¼Œç•™ä¸‹æé›·ä¸€ä¸ªäººå‘†ååœ¨é‚£é‡Œã€‚""",
        "extracted_json": [
            {
                "scene_id": "S01",
                "setting": "å†…æ™¯ å’–å•¡é¦† - æ—¥",
                "characters": ["æé›·", "éŸ©æ¢…æ¢…"],
                "scene_mission": "å±•ç°ä¸¤äººå…³ç³»çš„ç ´è£‚",
                "key_events": ["éŸ©æ¢…æ¢…å†·æ¼ åœ°åˆ°æ¥", "æé›·è¯•å›¾è§£é‡Šè¢«æ‹’ç»", "éŸ©æ¢…æ¢…å®£å¸ƒåˆ†æ‰‹ç¦»å¼€"],
                "info_change": [{"character": "è§‚ä¼—", "learned": "ä¸¤äººå…³ç³»å‡ºç°é‡å¤§å±æœº"}],
                "relation_change": [{"chars": ["æé›·", "éŸ©æ¢…æ¢…"], "from": "æ‹äºº", "to": "åˆ†æ‰‹"}],
                "key_object": [],
                "setup_payoff": {"setup_for": [], "payoff_from": []},
            }
        ],
        "scene_type": "standard",
        "source_file": "test_script_01.txt",
    }

    print("\nå‡†å¤‡æµ‹è¯•æ•°æ®...")
    print(f"  - æºæ–‡æœ¬é•¿åº¦: {len(test_case['source_text'])} å­—ç¬¦")
    print(f"  - åœºæ™¯æ•°é‡: {len(test_case['extracted_json'])}")
    print(f"  - åœºæ™¯ç±»å‹: {test_case['scene_type']}")

    # è¿è¡Œè¯„ä¼°
    print("\nå¼€å§‹è¯„ä¼°...")
    try:
        result = evaluator.evaluate_script(**test_case)

        # æ˜¾ç¤ºç»“æœ
        print("\n" + "=" * 60)
        print("è¯„ä¼°å®Œæˆï¼")
        print("=" * 60)

        print(f"\næ–‡ä»¶: {result.source_file}")
        print(f"è´¨é‡çº§åˆ«: {result.quality_level}")
        print(f"æ€»åˆ†: {result.overall_score:.3f}")
        print(f"é€šè¿‡: {'âœ… æ˜¯' if result.passed else 'âŒ å¦'}")

        print("\nå„é¡¹å¾—åˆ†:")
        print(f"  ç»“æ„éªŒè¯: {result.structure_score:.3f}")
        print(f"  åœºæ™¯è¾¹ç•Œ: {result.boundary_score:.3f}")
        print(f"  è§’è‰²æå–: {result.character_score:.3f}")
        print(f"  è¯­ä¹‰å‡†ç¡®: {result.semantic_score:.3f}")

        if result.issues:
            print(f"\nå‘ç° {len(result.issues)} ä¸ªé—®é¢˜:")
            for i, issue in enumerate(result.issues[:5], 1):
                print(f"  {i}. [{issue.get('severity', 'unknown')}] {issue.get('message', 'N/A')}")

        print("\næ”¹è¿›å»ºè®®:")
        for i, rec in enumerate(result.recommendations, 1):
            print(f"  {i}. {rec}")

        print("\nç»Ÿè®¡ä¿¡æ¯:")
        print(f"  åœºæ™¯æ€»æ•°: {result.total_scenes}")
        print(f"  è§’è‰²æ€»æ•°: {result.total_characters}")

        print("\n" + "=" * 60)
        print("æµ‹è¯•æˆåŠŸå®Œæˆï¼âœ…")
        print("=" * 60)

        return True

    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback

        traceback.print_exc()
        return False


def test_model_validation():
    """æµ‹è¯•Pydanticæ¨¡å‹éªŒè¯"""

    print("\n" + "=" * 60)
    print("æµ‹è¯•æ•°æ®æ¨¡å‹éªŒè¯")
    print("=" * 60)

    try:
        from models.scene_models import validate_script_json

        # æµ‹è¯•æœ‰æ•ˆæ•°æ®
        valid_scene = {
            "scene_id": "S01",
            "setting": "å†…æ™¯ å’–å•¡é¦† - æ—¥",
            "characters": ["è§’è‰²A", "è§’è‰²B"],
            "scene_mission": "æµ‹è¯•åœºæ™¯",
            "key_events": ["äº‹ä»¶1"],
        }

        print("\næµ‹è¯•æœ‰æ•ˆæ•°æ®...")
        result = validate_script_json(valid_scene, "standard")

        if result["valid"]:
            print("âœ… æœ‰æ•ˆæ•°æ®éªŒè¯é€šè¿‡")
        else:
            print("âŒ æœ‰æ•ˆæ•°æ®éªŒè¯å¤±è´¥")
            for error in result["errors"]:
                print(f"  é”™è¯¯: {error}")

        # æµ‹è¯•æ— æ•ˆæ•°æ®
        invalid_scene = {
            "scene_id": "åœºæ™¯1",  # æ ¼å¼é”™è¯¯
            "setting": "æŸä¸ªåœ°æ–¹",  # ç¼ºå°‘å†…å¤–æ™¯æ ‡è®°
            "characters": [],
            "scene_mission": "æµ‹è¯•",
            "key_events": [],  # ä¸èƒ½ä¸ºç©º
        }

        print("\næµ‹è¯•æ— æ•ˆæ•°æ®ï¼ˆåº”è¯¥å¤±è´¥ï¼‰...")
        result2 = validate_script_json(invalid_scene, "standard")

        if not result2["valid"]:
            print("âœ… æ— æ•ˆæ•°æ®æ­£ç¡®è¢«æ‹’ç»")
            print("  é”™è¯¯ä¿¡æ¯:")
            for error in result2["errors"]:
                print(f"    - {error}")
        else:
            print("âŒ æ— æ•ˆæ•°æ®æœªè¢«æ£€æµ‹åˆ°")

        print("\næ¨¡å‹éªŒè¯æµ‹è¯•å®Œæˆï¼âœ…")
        return True

    except Exception as e:
        print(f"\nâŒ æ¨¡å‹éªŒè¯æµ‹è¯•å¤±è´¥: {e}")
        import traceback

        traceback.print_exc()
        return False


def test_file_handler():
    """æµ‹è¯•æ–‡ä»¶å¤„ç†åŠŸèƒ½"""

    print("\n" + "=" * 60)
    print("æµ‹è¯•æ–‡ä»¶å¤„ç†åŠŸèƒ½")
    print("=" * 60)

    try:
        from utils.file_handler import FileHandler

        handler = FileHandler()

        # æµ‹è¯•å†™å…¥å’Œè¯»å–
        test_data = {"test": "æ•°æ®", "ä¸­æ–‡": "æ”¯æŒ"}

        test_file = "test_temp.json"

        print("\næµ‹è¯•JSONæ–‡ä»¶å†™å…¥...")
        handler.write_json_file(test_file, test_data)
        print("âœ… å†™å…¥æˆåŠŸ")

        print("\næµ‹è¯•JSONæ–‡ä»¶è¯»å–...")
        loaded_data = handler.read_json_file(test_file)
        print("âœ… è¯»å–æˆåŠŸ")

        if loaded_data == test_data:
            print("âœ… æ•°æ®ä¸€è‡´æ€§éªŒè¯é€šè¿‡")
        else:
            print("âŒ æ•°æ®ä¸ä¸€è‡´")

        # æ¸…ç†
        os.remove(test_file)
        print("\næ–‡ä»¶å¤„ç†æµ‹è¯•å®Œæˆï¼âœ…")
        return True

    except Exception as e:
        print(f"\nâŒ æ–‡ä»¶å¤„ç†æµ‹è¯•å¤±è´¥: {e}")
        import traceback

        traceback.print_exc()
        return False


def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""

    print("\nğŸš€ å¼€å§‹ç³»ç»Ÿæµ‹è¯•...\n")

    results = []

    # è¿è¡Œå„é¡¹æµ‹è¯•
    results.append(("æ–‡ä»¶å¤„ç†", test_file_handler()))
    results.append(("æ¨¡å‹éªŒè¯", test_model_validation()))
    results.append(("åŸºæœ¬è¯„ä¼°", test_basic_evaluation()))

    # æ±‡æ€»ç»“æœ
    print("\n" + "=" * 60)
    print("æµ‹è¯•æ±‡æ€»")
    print("=" * 60)

    for name, passed in results:
        status = "âœ… é€šè¿‡" if passed else "âŒ å¤±è´¥"
        print(f"  {name}: {status}")

    all_passed = all(result for _, result in results)

    if all_passed:
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼ç³»ç»Ÿè¿è¡Œæ­£å¸¸ã€‚")
        return 0
    else:
        print("\nâš ï¸ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯ã€‚")
        return 1


if __name__ == "__main__":
    sys.exit(main())
