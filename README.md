# å‰§æœ¬JSONè½¬æ¢è¯„ä¼°ç³»ç»Ÿ

## é¡¹ç›®ç®€ä»‹

è¿™æ˜¯ä¸€ä¸ªåŸºäº **DeepEval** æ¡†æ¶å’Œ **DeepSeek API** çš„è‡ªåŠ¨åŒ–è¯„ä¼°ç³»ç»Ÿï¼Œç”¨äºéªŒè¯å°†å‰§æœ¬æ–‡æœ¬è½¬æ¢ä¸ºç»“æ„åŒ–JSONæ•°æ®çš„è´¨é‡ã€‚ç³»ç»Ÿé‡‡ç”¨ä¸‰å±‚è¯„ä¼°æ¶æ„ï¼Œç»“åˆè§„åˆ™éªŒè¯ã€ç»Ÿè®¡åˆ†æå’ŒLLMè¯­ä¹‰è¯„ä¼°ï¼Œæä¾›å…¨é¢çš„è´¨é‡è¯„ä¼°ã€‚

## æ ¸å¿ƒç‰¹æ€§

- âœ… **ä¸‰å±‚è¯„ä¼°æ¶æ„**
  - ç»“æ„å±‚ï¼šJSONæ ¼å¼ã€å­—æ®µå®Œæ•´æ€§éªŒè¯
  - ç»Ÿè®¡å±‚ï¼šåœºæ™¯è¾¹ç•Œã€è§’è‰²è¯†åˆ«ç­‰æŒ‡æ ‡
  - è¯­ä¹‰å±‚ï¼šLLM-as-Judgeæ·±åº¦è¯­ä¹‰è¯„ä¼°

- ğŸ¯ **å¤šåœºæ™¯æ”¯æŒ**
  - åœºæ™¯1ï¼šæ ‡å‡†æ ¼å¼å‰§æœ¬è½¬JSON
  - åœºæ™¯2ï¼šæ•…äº‹å¤§çº²è½¬JSONï¼ˆæ›´çµæ´»çš„éªŒè¯è§„åˆ™ï¼‰

- ğŸ“Š **ä¸°å¯Œçš„è¯„ä¼°æŒ‡æ ‡**
  - åœºæ™¯è¾¹ç•Œå‡†ç¡®æ€§ï¼ˆF1, Precision, Recallï¼‰
  - è§’è‰²æå–å®Œæ•´æ€§å’Œä¸€è‡´æ€§
  - è¯­ä¹‰å‡†ç¡®æ€§ï¼ˆåœºæ™¯ä»»åŠ¡ã€å…³é”®äº‹ä»¶ã€ä¿¡æ¯å˜åŒ–ã€å…³ç³»å˜åŒ–ï¼‰
  - è‡ªä¸€è‡´æ€§è¯„ä¼°ï¼ˆå¯é€‰ï¼‰

- ğŸ¤– **DeepSeeké›†æˆ**
  - OpenAIå…¼å®¹çš„APIå°è£…
  - æ™ºèƒ½é‡è¯•æœºåˆ¶
  - æˆæœ¬è¿½è¸ªå’Œæ§åˆ¶
  - ç¼“å­˜ä¼˜åŒ–

- ğŸ“ **è¯¦ç»†çš„è¯„ä¼°æŠ¥å‘Š**
  - JSONæ ¼å¼è¯¦ç»†æŠ¥å‘Š
  - HTMLå¯è§†åŒ–æŠ¥å‘Š
  - é—®é¢˜å®šä½å’Œæ”¹è¿›å»ºè®®

## é¡¹ç›®ç»“æ„

```
script-evaluation-system/
â”‚
â”œâ”€â”€ src/                      # æºä»£ç 
â”‚   â”œâ”€â”€ models/               # Pydanticæ•°æ®æ¨¡å‹
â”‚   â”œâ”€â”€ metrics/              # è¯„ä¼°æŒ‡æ ‡
â”‚   â”œâ”€â”€ llm/                  # LLMé›†æˆ
â”‚   â”œâ”€â”€ evaluators/           # è¯„ä¼°å™¨
â”‚   â””â”€â”€ utils/                # å·¥å…·å‡½æ•°
â”‚
â”œâ”€â”€ tests/                    # æµ‹è¯•æ–‡ä»¶
â”‚   â”œâ”€â”€ unit/                 # å•å…ƒæµ‹è¯•
â”‚   â”œâ”€â”€ integration/          # é›†æˆæµ‹è¯•
â”‚   â””â”€â”€ test_data/            # æµ‹è¯•æ•°æ®
â”‚       â”œâ”€â”€ scene1/           # åœºæ™¯1æµ‹è¯•æ ·æœ¬
â”‚       â””â”€â”€ scene2/           # åœºæ™¯2æµ‹è¯•æ ·æœ¬
â”‚
â”œâ”€â”€ configs/                  # é…ç½®æ–‡ä»¶
â”‚   â”œâ”€â”€ default_config.yaml
â”‚   â”œâ”€â”€ evaluation_weights.yaml
â”‚   â””â”€â”€ deepseek_config.yaml
â”‚
â”œâ”€â”€ prompts/                  # Promptæ¨¡æ¿
â”‚   â”œâ”€â”€ scene1_extraction.txt
â”‚   â”œâ”€â”€ scene2_extraction.txt
â”‚   â”œâ”€â”€ boundary_evaluation.txt
â”‚   â””â”€â”€ semantic_evaluation.txt
â”‚
â”œâ”€â”€ scripts/                  # è„šæœ¬æ–‡ä»¶
â”‚   â””â”€â”€ test_system.py        # ç³»ç»Ÿæµ‹è¯•è„šæœ¬
â”‚
â”œâ”€â”€ docs/                     # æ–‡æ¡£
â”‚   â”œâ”€â”€ README.md
â”‚   â”œâ”€â”€ project_structure.md
â”‚   â”œâ”€â”€ quick_start_guide.md
â”‚   â””â”€â”€ script_eval_development_checklist.md
â”‚
â”œâ”€â”€ code-samples/             # ä»£ç ç¤ºä¾‹
â”‚
â”œâ”€â”€ outputs/                  # è¾“å‡ºç›®å½•ï¼ˆè‡ªåŠ¨ç”Ÿæˆï¼‰
â”‚   â”œâ”€â”€ reports/
â”‚   â””â”€â”€ logs/
â”‚
â”œâ”€â”€ requirements.txt          # ä¾èµ–åˆ—è¡¨
â”œâ”€â”€ .env.example              # ç¯å¢ƒå˜é‡ç¤ºä¾‹
â””â”€â”€ README.md                 # æœ¬æ–‡ä»¶
```

## å¿«é€Ÿå¼€å§‹

### 1. ç¯å¢ƒå‡†å¤‡

```bash
# å…‹éš†ä»“åº“
git clone <repository-url>
cd Script-JSON-Conversion-Evaluation-System

# åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate

# å®‰è£…ä¾èµ–
pip install -r requirements.txt
```

### 2. é…ç½®API

åˆ›å»º `.env` æ–‡ä»¶ï¼š

```bash
cp .env.example .env
```

ç¼–è¾‘ `.env` æ–‡ä»¶ï¼Œæ·»åŠ ä½ çš„ DeepSeek API Keyï¼š

```env
DEEPSEEK_API_KEY=your_api_key_here
```

### 3. è¿è¡Œæµ‹è¯•

```bash
# è¿è¡Œç³»ç»Ÿæµ‹è¯•ï¼ˆä¸éœ€è¦API Keyï¼‰
python scripts/test_system.py
```

### 4. è¿è¡Œè¯„ä¼°

```python
from src.evaluators.main_evaluator import ScriptEvaluator, EvaluationConfig

# é…ç½®è¯„ä¼°å™¨
config = EvaluationConfig(
    use_deepseek_judge=True,  # å¯ç”¨LLMè¯„ä¼°
    save_detailed_report=True
)

evaluator = ScriptEvaluator(config)

# å‡†å¤‡æ•°æ®
test_case = {
    "source_text": "ä½ çš„å‰§æœ¬æ–‡æœ¬...",
    "extracted_json": {...},  # æå–çš„JSON
    "scene_type": "standard",  # æˆ– "outline"
    "source_file": "test.txt"
}

# è¿è¡Œè¯„ä¼°
result = evaluator.evaluate_script(**test_case)

print(f"è¯„ä¼°å¾—åˆ†: {result.overall_score:.3f}")
print(f"è´¨é‡çº§åˆ«: {result.quality_level}")
```

## è¯„ä¼°ç¤ºä¾‹

### è¾“å…¥æ•°æ®

**å‰§æœ¬æ–‡æœ¬**ï¼ˆsource_textï¼‰:
```
å†…æ™¯ å’–å•¡é¦† - æ—¥

æé›·ååœ¨è§’è½é‡Œï¼Œä¸å®‰åœ°çœ‹ç€æ‰‹è¡¨ã€‚éŸ©æ¢…æ¢…æ¨é—¨è€Œå…¥ï¼Œè¡¨æƒ…å†·æ¼ ã€‚

éŸ©æ¢…æ¢…
ï¼ˆå†·æ·¡åœ°ï¼‰
ä½ æƒ³è¯´ä»€ä¹ˆï¼Ÿ
...
```

**æå–çš„JSON**ï¼ˆextracted_jsonï¼‰:
```json
[
  {
    "scene_id": "S01",
    "setting": "å†…æ™¯ å’–å•¡é¦† - æ—¥",
    "characters": ["æé›·", "éŸ©æ¢…æ¢…"],
    "scene_mission": "å±•ç°ä¸¤äººå…³ç³»çš„ç ´è£‚",
    "key_events": ["éŸ©æ¢…æ¢…å†·æ¼ åœ°åˆ°æ¥", "æé›·è¯•å›¾è§£é‡Šè¢«æ‹’ç»", "éŸ©æ¢…æ¢…å®£å¸ƒåˆ†æ‰‹ç¦»å¼€"],
    ...
  }
]
```

### è¾“å‡ºç»“æœ

```
è¯„ä¼°å®Œæˆï¼
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

æ–‡ä»¶: test_script_01.txt
è´¨é‡çº§åˆ«: ä¼˜ç§€
æ€»åˆ†: 0.875
é€šè¿‡: âœ… æ˜¯

å„é¡¹å¾—åˆ†:
  ç»“æ„éªŒè¯: 0.950
  åœºæ™¯è¾¹ç•Œ: 0.850
  è§’è‰²æå–: 0.900
  è¯­ä¹‰å‡†ç¡®: 0.800

ç»Ÿè®¡ä¿¡æ¯:
  åœºæ™¯æ€»æ•°: 1
  è§’è‰²æ€»æ•°: 2

æ”¹è¿›å»ºè®®:
  1. åœºæ™¯ä»»åŠ¡æè¿°å‡†ç¡®åˆ°ä½
  2. å…³é”®äº‹ä»¶è¦†ç›–å®Œæ•´
```

## æ ¸å¿ƒæ¨¡å—è¯´æ˜

### 1. æ•°æ®æ¨¡å‹ (src/models/)

ä½¿ç”¨ Pydantic å®šä¹‰ä¸¥æ ¼çš„æ•°æ®æ¨¡å‹ï¼š
- `SceneInfo`: åœºæ™¯1ï¼ˆæ ‡å‡†å‰§æœ¬ï¼‰æ¨¡å‹
- `OutlineSceneInfo`: åœºæ™¯2ï¼ˆæ•…äº‹å¤§çº²ï¼‰æ¨¡å‹
- è‡ªåŠ¨éªŒè¯å­—æ®µæ ¼å¼ã€ç±»å‹ã€å–å€¼èŒƒå›´

### 2. è¯„ä¼°æŒ‡æ ‡ (src/metrics/)

å®ç°å¤šç§è¯„ä¼°æŒ‡æ ‡ï¼š
- `SceneBoundaryMetric`: åœºæ™¯è¾¹ç•Œè¯„ä¼°
- `CharacterExtractionMetric`: è§’è‰²æå–è¯„ä¼°
- `SelfConsistencyMetric`: è‡ªä¸€è‡´æ€§è¯„ä¼°

### 3. LLMé›†æˆ (src/llm/)

DeepSeek APIå®¢æˆ·ç«¯å°è£…ï¼š
- OpenAIå…¼å®¹æ¥å£
- æ™ºèƒ½é‡è¯•æœºåˆ¶
- Tokenä½¿ç”¨ç»Ÿè®¡
- æˆæœ¬è¿½è¸ª

### 4. è¯„ä¼°å™¨ (src/evaluators/)

åè°ƒæ•´ä¸ªè¯„ä¼°æµç¨‹ï¼š
- ä¸‰å±‚è¯„ä¼°æ¶æ„å®ç°
- åˆ†æ•°èšåˆå’Œæƒé‡ç®¡ç†
- æŠ¥å‘Šç”Ÿæˆ

## é…ç½®è¯´æ˜

### è¯„ä¼°æƒé‡é…ç½®

ç¼–è¾‘ `configs/evaluation_weights.yaml`:

```yaml
weights:
  structure: 0.25    # ç»“æ„éªŒè¯æƒé‡
  boundary: 0.25     # åœºæ™¯è¾¹ç•Œæƒé‡
  character: 0.25    # è§’è‰²æå–æƒé‡
  semantic: 0.25     # è¯­ä¹‰å‡†ç¡®æƒé‡
```

### DeepSeek APIé…ç½®

ç¼–è¾‘ `configs/deepseek_config.yaml`:

```yaml
api:
  model: "deepseek-chat"
  temperature: 0.1
  max_retries: 3

cost_tracking:
  enabled: true
  daily_limit: 100.0  # æ¯æ—¥é¢„ç®—ï¼ˆäººæ°‘å¸ï¼‰
```

## å¼€å‘æŒ‡å—

### æ·»åŠ æ–°çš„è¯„ä¼°æŒ‡æ ‡

1. åœ¨ `src/metrics/` åˆ›å»ºæ–°çš„æŒ‡æ ‡ç±»
2. ç»§æ‰¿ `deepeval.metrics.BaseMetric`
3. å®ç° `measure()` å’Œ `a_measure()` æ–¹æ³•
4. åœ¨ä¸»è¯„ä¼°å™¨ä¸­é›†æˆ

### è‡ªå®šä¹‰Promptæ¨¡æ¿

ç¼–è¾‘ `prompts/` ç›®å½•ä¸‹çš„æ¨¡æ¿æ–‡ä»¶ï¼Œè‡ªå®šä¹‰è¯„ä¼°æ ‡å‡†å’Œè¾“å‡ºæ ¼å¼ã€‚

### è¿è¡Œæµ‹è¯•

```bash
# å•å…ƒæµ‹è¯•
pytest tests/unit/

# é›†æˆæµ‹è¯•
pytest tests/integration/

# ç³»ç»Ÿæµ‹è¯•
python scripts/test_system.py
```

## æ–‡æ¡£

- ğŸ“– [é¡¹ç›®ç»“æ„è¯´æ˜](docs/project_structure.md)
- ğŸš€ [å¿«é€Ÿå¼€å§‹æŒ‡å—](docs/quick_start_guide.md)
- âœ… [å¼€å‘ä»»åŠ¡æ¸…å•](docs/script_eval_development_checklist.md)

## æŠ€æœ¯æ ˆ

- **è¯„ä¼°æ¡†æ¶**: DeepEval 0.21+
- **LLM Provider**: DeepSeek API
- **æ•°æ®éªŒè¯**: Pydantic 2.5+
- **APIå®¢æˆ·ç«¯**: OpenAI Python SDK
- **é…ç½®ç®¡ç†**: PyYAML
- **æ•°æ®å¤„ç†**: Pandas, NumPy
- **æµ‹è¯•æ¡†æ¶**: Pytest

## è·¯çº¿å›¾

### å·²å®Œæˆ
- [x] åŸºç¡€é¡¹ç›®æ¶æ„
- [x] Pydanticæ•°æ®æ¨¡å‹
- [x] DeepSeekå®¢æˆ·ç«¯å°è£…
- [x] ä¸‰å±‚è¯„ä¼°æ¶æ„
- [x] åŸºç¡€è¯„ä¼°æŒ‡æ ‡
- [x] æŠ¥å‘Šç”Ÿæˆç³»ç»Ÿ

### è¿›è¡Œä¸­
- [ ] å®Œæ•´çš„å•å…ƒæµ‹è¯•è¦†ç›–
- [ ] æ‰¹é‡è¯„ä¼°è„šæœ¬
- [ ] æ€§èƒ½ä¼˜åŒ–ï¼ˆå¼‚æ­¥ã€ç¼“å­˜ï¼‰

### æœªæ¥è®¡åˆ’
- [ ] Webç•Œé¢
- [ ] è¯„ä¼°ç»“æœå¯è§†åŒ–ä»ªè¡¨æ¿
- [ ] æ›´å¤šè¯„ä¼°æŒ‡æ ‡ï¼ˆMINEAã€å¼‚å¸¸æ£€æµ‹ç­‰ï¼‰
- [ ] å¤šè¯­è¨€æ”¯æŒ
- [ ] Dockerå®¹å™¨åŒ–éƒ¨ç½²

## è´¡çŒ®

æ¬¢è¿è´¡çŒ®ä»£ç ã€æŠ¥å‘Šé—®é¢˜æˆ–æå‡ºå»ºè®®ï¼

## è®¸å¯è¯

MIT License

## è”ç³»æ–¹å¼

å¦‚æœ‰é—®é¢˜æˆ–å»ºè®®ï¼Œè¯·é€šè¿‡ä»¥ä¸‹æ–¹å¼è”ç³»ï¼š
- æäº¤ Issue
- å‘èµ· Pull Request

---

**å¼€å‘å›¢é˜Ÿ** | 2024
